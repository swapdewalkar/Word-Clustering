URL:http://www.technewsworld.com/story/84544.html
TITLE:Data Watchdog Cautions Google and UK Health Partner | Tech Law | TechNewsWorld
META-KEYWORDS:healthcare,artificial intelligence,Google,advertising
DATE:May 19, 2017 8:41 AM PT
DOC ID:448
CONTENT:A British data watchdog has raised questions about whether it was appropriate for a healthcare trust to share data on 1.6 million patients with DeepMind Health, an artificial intelligence company owned by Google.The trust shared the data in connection with the test phase of Streams, an app designed to diagnose acute kidney injuries. However, the sharing was performed without an appropriate legal basis, Sky News reported earlier this week, based on a letter it obtained.The National Data Guardian at the Department of Health earlier this year sent the letter to Stephen Powis, the medical director of the Royal Free Hospital in London, which provided the patients' records to DeepMind. The National Data Guardian safeguards the use of healthcare information in the UK.The UK's Information Commissioner's Office also has been probing the matter, and is expected to complete its investigation soon.One of the concerns since the launch of the Streams project has been whether the data shared with Google would be used appropriately."The data used to provide the app has always been strictly controlled by the Royal Free and has never been used for commercial purposes or combined with Google products, services or ads -- and never will be," DeepMind said in a statement provided to TechNewsWorld by spokesperson Ruth Barnett.DeepMind also said that it recognizes that there needs to be much more public engagement and discussion about new technology in the National Health System, and that it wants to be one of the most transparent companies working in NHS IT.Royal Free takes seriously the conclusions of the NDG, the hospital said in a statement provided to TechNewsWorld by spokesperson Ian Lloyd. It is pleased that the NDG asked the Department of Health to look closely at the regulatory framework and guidance provided to organizations engaging in innovation.Streams is a new technology, and there are always lessons that  can be learned from pioneering work, Royal Free noted.However, the hospital took a safety-first approach in testing Streams with real data, in order to check that the app was presenting patient information accurately and safely before being deployed in a live patient setting, it maintained.Real patient data is routinely used in the NHS to check new systems are working properly before turning them fully live, Royal Free explained, adding that no responsible hospital would deploy a system that hadn't been thoroughly tested. The controversy over Streams may have less to do with patient privacy and more to do with Google."If this hadn't involved a GoFA (Google Facebook Amazon), I wonder if this would have evoked such an outcry," observed Jessica Groopman, a principal analyst at Tractica."In this case, DeepMind's affiliation with Google may have hurt it," she told TechNewsWorld.Although there's no evidence of data abuse by DeepMind, the future fate of personal healthcare information is an issue that has raised concerns, Groopman noted."There's a concern that once these sorts of applications -- and use of these sets of big, personal data -- become more commonplace, it will lead to commercial use of the data," she said. "I'm sure that Google and DeepMind understand that anything they do is going to be hyperscrutinized through this lens of advertising revenue." Health apps can have real benefits for individuals, as Streams illustrates, but they need data to do it, which can raise privacy questions."When you're looking at deep learning applications, the amount of data that is required to train these models is huge,"  Groopman explained. "That's why these kinds of tensions will continue to occur."Patient information must be given the highest level of protection within an organization, argued Lee Kim, privacy and security director at the Healthcare Information and Management Systems Society."But there must be a balance between restrictions and availability of the data," she told TechNewsWorld."An immense amount of progress can be made in healthcare and self-care through the use of machine learning and artificial intelligence to deliver more accessible, affordable and effective care solutions to the market," noted Jeff Dachis, CEO of One Drop, a platform for the personal management of diabetes."We must always respect data privacy and the individual's right to that privacy," he told TechNewsWorld, "but not halt all the much needed progress in this area under the guise of data privacy."John P. Mello Jr. has been an ECT News Network reportersince 2003. His areas of focus include cybersecurity, IT issues, privacy, e-commerce, social media, artificial intelligence, big data and consumer electronics.  He has written and edited for numerous publications, including the Boston Business Journal, theBoston Phoenix, Megapixel.Net and GovernmentSecurity News. Email John.